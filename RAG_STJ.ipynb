{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg2ei1zd/yLSsYGiexWNrR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandabarrigosse/LIA/blob/main/RAG_STJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4jhueIGI956g",
        "outputId": "dfb7a5a8-1bb7-4110-91a4-3e188192f2f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando as dependecias"
      ],
      "metadata": {
        "id": "VEY-N7eZ_Kco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf langchain sentence-transformers faiss-cpu transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OPJewC2z_OdL",
        "outputId": "140e67a3-3651-4fc2-d73a-eb0d61b0d967"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.7)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "import re\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "import torch\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "szdQXcnZABxF"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extrair sumulas do pdf"
      ],
      "metadata": {
        "id": "UwTEC_SZBAPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def extrair_sumulas(pdf_path):\n",
        "    sumulas = []\n",
        "    text_buffer = \"\"\n",
        "\n",
        "    # Abrir o PDF com PyMuPDF\n",
        "    doc = fitz.open(pdf_path)\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc[page_num]\n",
        "        text_buffer += page.get_text(\"text\") + \"\\n\"\n",
        "\n",
        "        # Processar o buffer a cada 100 páginas para reduzir memória\n",
        "        if page_num % 100 == 0 or page_num == len(doc) - 1:\n",
        "            padrao = r'SÚMULA\\s+(\\d+)\\s*\\n\\s*([^\\n]+?)\\s*\\n\\s*(?:Enunciado:)?\\s*\\n(.*?)(?=\\s*(?:SÚMULA\\s+\\d+|INTEIRO TEOR DAS SÚMULAS|Referências Legislativas:|Anexos|\\Z))'\n",
        "            matches = re.findall(padrao, text_buffer, re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "            for match in matches:\n",
        "                numero = match[0]\n",
        "                area_titulo = match[1].strip()\n",
        "                enunciado = match[2].strip()\n",
        "                sumulas.append({\n",
        "                    \"numero\": numero,\n",
        "                    \"area_titulo\": area_titulo,\n",
        "                    \"enunciado\": enunciado\n",
        "                })\n",
        "\n",
        "            # Limpar buffer\n",
        "            text_buffer = \"\"\n",
        "\n",
        "    doc.close()\n",
        "\n",
        "    output_dir = '/content'\n",
        "\n",
        "    with open(os.path.join(output_dir, 'sumulas_completas.json'), 'w', encoding='utf-8') as f:\n",
        "        json.dump(sumulas, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "\n",
        "    return sumulas"
      ],
      "metadata": {
        "id": "Qk1vLTh4A6pY"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def criar_vector_store(sumulas, index_path=\"/content/sumulas_index\"):\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"neuralmind/bert-base-portuguese-cased\")\n",
        "    texts = [f\"Súmula {s['numero']} - {s['area_titulo']}: {s['enunciado']}\" for s in sumulas]\n",
        "    metadatas = [{\"numero\": s[\"numero\"], \"area_titulo\": s[\"area_titulo\"]} for s in sumulas]\n",
        "\n",
        "    vectorstore = FAISS.from_texts(texts, embeddings, metadatas=metadatas)\n",
        "    vectorstore.save_local(index_path)\n",
        "    return vectorstore"
      ],
      "metadata": {
        "id": "7y94LMULBSil"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def configurar_rag(vectorstore):\n",
        "    model_name = \"google/flan-t5-base\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    text_generation_pipeline = pipeline(\n",
        "        \"text2text-generation\",\n",
        "        model=model_name,\n",
        "        tokenizer=tokenizer,\n",
        "        max_length=512,\n",
        "        device=0 if torch.cuda.is_available() else -1\n",
        "    )\n",
        "    llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
        "        return_source_documents=True\n",
        "    )\n",
        "    return qa_chain, tokenizer"
      ],
      "metadata": {
        "id": "9UTG8OtDBYIH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verificar_ementa(qa_chain, tokenizer, ementa):\n",
        "    prompt = f\"\"\"\n",
        "    Verifique se existe alguma súmula do STJ em consonância com a ementa abaixo. Considere o alinhamento jurídico, incluindo princípios e legislações citadas. Liste as súmulas relevantes, explique o raciocínio e indique se há enquadramento total, parcial ou nenhum. Se nenhuma súmula for aplicável, explique por quê.\n",
        "\n",
        "    Ementa: {ementa}\n",
        "    \"\"\"\n",
        "    # Truncar prompt para 400 tokens\n",
        "    tokens = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=400)\n",
        "    truncated_prompt = tokenizer.decode(tokens[\"input_ids\"][0], skip_special_tokens=True)\n",
        "\n",
        "    resultado = qa_chain.invoke({\"query\": truncated_prompt})\n",
        "    return resultado[\"result\"], resultado[\"source_documents\"]"
      ],
      "metadata": {
        "id": "4gvaIC4iBbWe"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/SumulasSTJ.pdf\"\n",
        "sumulas = extrair_sumulas(pdf_path)\n",
        "print(f\"Extraídas {len(sumulas)} súmulas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYlg-_kZBez5",
        "outputId": "db04e4bf-5412-4c9b-928f-3209fb397e3e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraídas 555 súmulas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_path = \"/content/sumulas_index\"\n",
        "if os.path.exists(index_path):\n",
        "    vectorstore = FAISS.load_local(index_path, HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"), allow_dangerous_deserialization=True)\n",
        "else:\n",
        "    vectorstore = criar_vector_store(sumulas, index_path)\n",
        "\n",
        "qa_chain, tokenizer = configurar_rag(vectorstore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpv3ljoABjXY",
        "outputId": "f2620355-4a0f-41a3-fb81-17de09e19b69"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ementa = \"\"\"\n",
        "PRISÃO PREVENTIVA. PORTE ILEGAL DE ARMA DE FOGO DE USO PERMITIDO, TRÁFICO DE DROGAS E ASSOCIAÇÃO PARA O TRÁFICO. GARANTIA DA ORDEM PÚBLICA. CONVERSÃO EX OFFICIO DA PRISÃO EM FLAGRANTE EM PREVENTIVA. IMPOSSIBILIDADE. NECESSIDADE DE REQUERIMENTO PRÉVIO OU PELO MINISTÉRIO PÚBLICO OU PELO QUERELANTE, OU PELO ASSISTENTE OU, POR FIM, MEDIANTE REPRESENTAÇÃO DA AUTORIDADE POLICIAL. [...] No caso, a decisão agravada deve ser mantida, uma vez que não é possível a decretação da prisão preventiva de ofício em face do que dispõe a Lei n. 13.964/2019, mesmo se decorrente de prisão em flagrante e se não tiver ocorrido audiência de custódia. Isso porque não existe diferença entre a conversão da prisão em flagrante em preventiva e a decretação da prisão preventiva como uma primeira prisão (EDcl no AgRg no HC n. 653.425/MG, de minha relatoria, Sexta Turma, DJe 19/11/2021)\n",
        "\"\"\"\n",
        "resposta, documentos = verificar_ementa(qa_chain, tokenizer, ementa)\n",
        "print(\"Resposta:\", resposta)\n",
        "print(\"Súmulas recuperadas:\", [doc.metadata for doc in documentos])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx3GdjDYCX4j",
        "outputId": "013cb8aa-d3b2-4132-e088-e23ce1d3c660"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resposta: EX OFFICIO DA PRISO EM FLAGRANTE EM PREVENTIVA. IMPOSSIBILIDADE. NECESSIDADE DE REQUERIMENTO PRÉVIO OU PELO MINISTÉRIO PBLICO OU PELO QUERELANTE, OU PELO ASSISTENTE OU, POR FIM, MEDIANTE REPRESENTAO DA AUTORIDADE POLICIAL\n",
            "Súmulas recuperadas: [{'numero': '213', 'area_titulo': 'DIREITO TRIBUTÁRIO - COMPENSAÇÃO DE CRÉDITOS TRIBUTÁRIOS'}, {'numero': '191', 'area_titulo': 'DIREITO PENAL - PRESCRIÇÃO'}, {'numero': '12', 'area_titulo': 'DIREITO ADMINISTRATIVO - DESAPROPRIAÇÃO'}]\n"
          ]
        }
      ]
    }
  ]
}